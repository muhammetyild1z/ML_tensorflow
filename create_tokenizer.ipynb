{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5580f008-0d18-4511-b33c-e273dba67c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f661ff51-fc4c-4817-9c6e-ae4da55c5e5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#yorum dosyasini ac ve csv formatinda tekrar olustur\n",
    "with open('comments_1.txt', 'r', encoding='utf-8') as txt_file:\n",
    "    yorumlar = txt_file.readlines()  \n",
    "\n",
    "    with open('comment_tbl.csv', 'w', encoding='utf-8') as csv_file:\n",
    "        for line in yorumlar:\n",
    "            parts = line.split('\\t')  \n",
    "            csv_file.write(parts[0].lower() + \"\\t\" + re.sub(r'[^\\w\\s]', '', parts[1].lower().replace(\":\", \"\").replace(\"'\", \"\").replace(\"\\t\", \" \").strip()) + \"\\n\")\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7e5271-4dbb-4aca-a011-8dce242afbbb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   skore                                            comment\n",
      "0    0.8                                      ürün kaliteli\n",
      "1    1.0                         güzel ürün teşekkür ederim\n",
      "2    1.0                                              güzel\n",
      "3    1.0  sevgilime aldım cok yakıştı kumaşı duruşu cok ...\n",
      "4    1.0                                          çok güzel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('comment_tbl.csv',sep='\\t')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa90822-0750-4c24-b24e-e1de6576d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skor da 0.8 uzerini 1 olarakd degistirip aliyoruz \n",
    "# skor 0.5 altini 0.0 yapiyoruz ve elimizde sadece 0.6 1.0 ve 0.0 kaliyor\n",
    "\n",
    "data.loc[data['skore']>0.7,'skore']=1.0\n",
    "data.loc[data['skore']<0.5,'skore']=0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde06a39-18af-4d51-b373-420fa6370907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.0 olan skorlari aliyoruz ve 0.0 lari sonra birlestiriyoruz\n",
    "# sonra veriyi yeni csv dosyasina yaziyoruz\n",
    "data_frame_1=data[data.skore==1.0]\n",
    "data_frame_0=data[data.skore==0.0]\n",
    "data_frame=pd.concat([data_frame_1,data_frame_0],ignore_index=True)\n",
    "data_frame=shuffle(data_frame)\n",
    "data_frame.to_csv('comment__learn.csv',sep='\\t',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b865b-10ca-4016-8c5e-3a0bff2f3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer kaydetme lib\n",
    "import pickle\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466d452a-6c4c-44ef-ba20-39fcc6a83504",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenlestirme alani\n",
    "##JSON KAYDETME\n",
    "from itertools import islice\n",
    "######\n",
    "\n",
    "dataframe= pd.read_csv('comment__learn.csv',sep='\\t')\n",
    "list__comment = dataframe['comment'].fillna('').values.tolist()\n",
    "list__skore=dataframe['skore'].values.tolist()\n",
    "tokenizer=Tokenizer(num_words=None,  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',lower=True,split=' ', char_level=False, oov_token=None, document_count=0)\n",
    "tokenizer.fit_on_texts(list__comment)\n",
    "def take (n, iterable):\n",
    "    \"return first items itareble as a list\"\n",
    "    return  islice(iterable,n)\n",
    "\n",
    "n_items= take(70000, tokenizer.word_index.items())\n",
    "## ciktiyi al kopyala bir dosyaya ya yaz json olarak kaydet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437d894-f8d5-4e46-9c4f-5f52e63c8a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b250e-05d9-4745-8b7d-4b4bc69da655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
